"""
æœ¬åœ° Embedding æ¨¡å‹æœåŠ¡
ä½¿ç”¨ sentence-transformers æ›¿ä»£ OpenAI Embedding API
"""
from sentence_transformers import SentenceTransformer
from typing import List, Union
import numpy as np


class LocalEmbeddingService:
    """æœ¬åœ° Embedding æœåŠ¡"""
    
    def __init__(self, model_name: str = "paraphrase-multilingual-MiniLM-L12-v2"):
        """
        åˆå§‹åŒ–æœ¬åœ° Embedding æ¨¡å‹
        
        æ¨èçš„ä¸­æ–‡å‹å¥½æ¨¡å‹ï¼š
        - paraphrase-multilingual-MiniLM-L12-v2 (384ç»´ï¼Œæ”¯æŒ50+è¯­è¨€ï¼Œé€Ÿåº¦å¿«)
        - distiluse-base-multilingual-cased-v2 (512ç»´ï¼Œæ”¯æŒ15+è¯­è¨€)
        - all-MiniLM-L6-v2 (384ç»´ï¼Œè‹±æ–‡ä¼˜åŒ–ï¼Œé€Ÿåº¦æœ€å¿«)
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ° Embedding æ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.embedding_dimension = self.model.get_sentence_embedding_dimension()
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå‘é‡ç»´åº¦: {self.embedding_dimension}")
    
    def create_embedding(self, text: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """
        åˆ›å»ºæ–‡æœ¬çš„ Embedding
        
        Args:
            text: å•ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²æˆ–æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å•ä¸ªå‘é‡æˆ–å‘é‡åˆ—è¡¨
        """
        if isinstance(text, str):
            # å•ä¸ªæ–‡æœ¬
            embedding = self.model.encode(text, convert_to_numpy=True)
            return embedding.tolist()
        else:
            # æ‰¹é‡æ–‡æœ¬
            embeddings = self.model.encode(text, convert_to_numpy=True, show_progress_bar=True)
            return embeddings.tolist()
    
    def get_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.embedding_dimension


# å…¨å±€å•ä¾‹
_embedding_service = None


def get_embedding_service(model_name: str = "paraphrase-multilingual-MiniLM-L12-v2") -> LocalEmbeddingService:
    """
    è·å– Embedding æœåŠ¡å•ä¾‹
    
    Args:
        model_name: æ¨¡å‹åç§°
        
    Returns:
        LocalEmbeddingService å®ä¾‹
    """
    global _embedding_service
    if _embedding_service is None:
        _embedding_service = LocalEmbeddingService(model_name)
    return _embedding_service


# å…¼å®¹ OpenAI API çš„æ¥å£
def create_embeddings(texts: Union[str, List[str]], model: str = None) -> dict:
    """
    åˆ›å»º Embeddingï¼ˆå…¼å®¹ OpenAI API æ ¼å¼ï¼‰
    
    Args:
        texts: æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œæœ¬åœ°æ¨¡å‹å¿½ç•¥æ­¤å‚æ•°ï¼‰
        
    Returns:
        ç¬¦åˆ OpenAI API æ ¼å¼çš„å“åº”
    """
    service = get_embedding_service()
    
    if isinstance(texts, str):
        texts = [texts]
    
    embeddings = service.create_embedding(texts)
    
    # æ„é€ ç±»ä¼¼ OpenAI API çš„å“åº”æ ¼å¼
    return {
        'data': [
            {
                'embedding': emb,
                'index': i,
                'object': 'embedding'
            }
            for i, emb in enumerate(embeddings)
        ],
        'model': 'local-embedding',
        'object': 'list',
        'usage': {
            'prompt_tokens': sum(len(t.split()) for t in texts),
            'total_tokens': sum(len(t.split()) for t in texts)
        }
    }


if __name__ == '__main__':
    # æµ‹è¯•
    print("=" * 60)
    print("æœ¬åœ° Embedding æ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    service = get_embedding_service()
    
    # æµ‹è¯•ä¸­æ–‡
    test_texts = [
        "æˆ‘æ˜¯ä¸€åPythonå·¥ç¨‹å¸ˆï¼Œæ“…é•¿åç«¯å¼€å‘",
        "å¯»æ‰¾å…¨æ ˆå¼€å‘å²—ä½ï¼Œç†Ÿæ‚‰Reactå’ŒDjango",
        "æœ‰5å¹´å·¥ä½œç»éªŒçš„èµ„æ·±å¼€å‘è€…"
    ]
    
    print(f"\næµ‹è¯•æ–‡æœ¬æ•°é‡: {len(test_texts)}")
    embeddings = service.create_embedding(test_texts)
    
    print(f"ç”Ÿæˆçš„å‘é‡æ•°é‡: {len(embeddings)}")
    print(f"å‘é‡ç»´åº¦: {len(embeddings[0])}")
    print(f"ç¬¬ä¸€ä¸ªå‘é‡çš„å‰10ä¸ªå€¼: {embeddings[0][:10]}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    from numpy import dot
    from numpy.linalg import norm
    
    def cosine_similarity(a, b):
        return dot(a, b) / (norm(a) * norm(b))
    
    print("\nç›¸ä¼¼åº¦çŸ©é˜µ:")
    for i, text_i in enumerate(test_texts):
        for j, text_j in enumerate(test_texts):
            sim = cosine_similarity(embeddings[i], embeddings[j])
            print(f"  æ–‡æœ¬{i+1} vs æ–‡æœ¬{j+1}: {sim:.4f}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
