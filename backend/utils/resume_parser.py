"""
ç®€å†ç»“æ„åŒ–è§£æå™¨
æ–¹æ¡ˆ1: è§„åˆ™æå–ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ + å…³é”®è¯åŒ¹é…ï¼‰
æ–¹æ¡ˆ2: å¤§æ¨¡å‹æå–ï¼ˆOpenAI GPTï¼‰
æ–¹æ¡ˆ3: æ··åˆæ–¹æ¡ˆï¼ˆæ¨èï¼‰
"""
import re
from typing import Dict, List, Optional
import jieba.analyse


class RuleBasedParser:
    """åŸºäºè§„åˆ™çš„ç®€å†è§£æå™¨ï¼ˆä¸éœ€è¦å¤§æ¨¡å‹ï¼‰"""
    
    def __init__(self):
        # å¸¸è§æŠ€èƒ½å…³é”®è¯åº“
        self.tech_keywords = {
            'languages': ['Python', 'Java', 'JavaScript', 'Go', 'C++', 'C#', 'PHP', 'Ruby', 'Swift', 'Kotlin'],
            'frameworks': ['Django', 'Flask', 'FastAPI', 'Spring', 'React', 'Vue', 'Angular', 'Express'],
            'databases': ['MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'SQL Server', 'Elasticsearch'],
            'devops': ['Docker', 'Kubernetes', 'Jenkins', 'Git', 'CI/CD', 'AWS', 'Azure', 'Linux'],
            'other': ['å¾®æœåŠ¡', 'RESTful', 'gRPC', 'é«˜å¹¶å‘', 'åˆ†å¸ƒå¼', 'æ¶ˆæ¯é˜Ÿåˆ—', 'Kafka', 'RabbitMQ']
        }
        
        # å­¦å†å…³é”®è¯
        self.education_keywords = ['æœ¬ç§‘', 'ç¡•å£«', 'åšå£«', 'å­¦å£«', 'å¤§ä¸“', 'ä¸“ç§‘', 'ç ”ç©¶ç”Ÿ']
        
        # ç« èŠ‚æ ‡é¢˜å…³é”®è¯
        self.section_markers = {
            'skills': ['æŠ€èƒ½', 'ä¸“ä¸šæŠ€èƒ½', 'æŠ€æœ¯æ ˆ', 'æŒæ¡æŠ€èƒ½', 'ç†Ÿæ‚‰æŠ€èƒ½'],
            'experience': ['å·¥ä½œç»éªŒ', 'é¡¹ç›®ç»éªŒ', 'å·¥ä½œç»å†', 'èŒä¸šç»å†', 'ä»»èŒç»å†'],
            'education': ['æ•™è‚²èƒŒæ™¯', 'æ•™è‚²ç»å†', 'å­¦å†', 'æ¯•ä¸šé™¢æ ¡'],
            'projects': ['é¡¹ç›®ç»éªŒ', 'é¡¹ç›®ç»å†', 'ä¸»è¦é¡¹ç›®'],
            'summary': ['ä¸ªäººç®€ä»‹', 'è‡ªæˆ‘è¯„ä»·', 'ä¸ªäººä»‹ç»', 'ç®€ä»‹']
        }
    
    def extract_basic_info(self, text: str) -> Dict:
        """æå–åŸºæœ¬ä¿¡æ¯"""
        info = {
            'name': None,
            'phone': None,
            'email': None,
            'years_experience': 0
        }
        
        # æå–ç”µè¯
        phone_pattern = r'1[3-9]\d{9}'
        phone_match = re.search(phone_pattern, text)
        if phone_match:
            info['phone'] = phone_match.group()
        
        # æå–é‚®ç®±
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_match = re.search(email_pattern, text)
        if email_match:
            info['email'] = email_match.group()
        
        # æå–å·¥ä½œå¹´é™
        years_patterns = [
            r'(\d+)\s*å¹´.*?å·¥ä½œç»éªŒ',
            r'(\d+)\s*å¹´.*?ç»éªŒ',
            r'(\d+)\+?\s*years?.*?experience',
        ]
        for pattern in years_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                info['years_experience'] = int(match.group(1))
                break
        
        return info
    
    def extract_skills(self, text: str) -> List[str]:
        """æå–æŠ€èƒ½åˆ—è¡¨"""
        skills = []
        
        # æ–¹æ³•1: ä»æŠ€èƒ½å…³é”®è¯åº“åŒ¹é…
        text_lower = text.lower()
        for category, keywords in self.tech_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower or keyword in text:
                    if keyword not in skills:
                        skills.append(keyword)
        
        # æ–¹æ³•2: æ‰¾åˆ°"æŠ€èƒ½"ç« èŠ‚ï¼Œæå–è¯¥æ®µè½
        for marker in self.section_markers['skills']:
            pattern = f'{marker}[ï¼š:](.*?)(?=\n\n|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|$)'
            match = re.search(pattern, text, re.DOTALL)
            if match:
                section_text = match.group(1)
                # åˆ†è¯æå–
                keywords = jieba.analyse.extract_tags(section_text, topK=15)
                skills.extend([k for k in keywords if k not in skills])
                break
        
        return skills
    
    def extract_experience_sections(self, text: str) -> List[Dict]:
        """æå–å·¥ä½œç»éªŒæ®µè½"""
        experiences = []
        
        # æŸ¥æ‰¾"å·¥ä½œç»éªŒ"ç« èŠ‚
        for marker in self.section_markers['experience']:
            # åŒ¹é…æ•´ä¸ªç»éªŒç« èŠ‚
            pattern = f'{marker}[ï¼š:](.*?)(?=æ•™è‚²èƒŒæ™¯|é¡¹ç›®ç»éªŒ|æŠ€èƒ½|$)'
            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            
            if match:
                exp_section = match.group(1)
                
                # æŒ‰æ—¥æœŸæˆ–å…¬å¸ååˆ†å‰²
                # å¸¸è§æ ¼å¼: 2020.01 - 2023.05  XXå…¬å¸  åç«¯å·¥ç¨‹å¸ˆ
                exp_pattern = r'(\d{4}[.\-/]\d{1,2}.*?(?:\d{4}[.\-/]\d{1,2}|è‡³ä»Š))\s*([^\n]+)'
                
                for exp_match in re.finditer(exp_pattern, exp_section):
                    date_range = exp_match.group(1).strip()
                    content = exp_match.group(2).strip()
                    
                    # æå–å…¬å¸å’ŒèŒä½
                    parts = content.split()
                    company = parts[0] if parts else ''
                    position = parts[1] if len(parts) > 1 else ''
                    
                    experiences.append({
                        'date_range': date_range,
                        'company': company,
                        'position': position,
                        'description': content
                    })
                
                break
        
        return experiences
    
    def extract_education(self, text: str) -> Dict:
        """æå–æ•™è‚²èƒŒæ™¯"""
        education = {
            'degree': None,
            'school': None,
            'major': None
        }
        
        # æŸ¥æ‰¾å­¦å†å…³é”®è¯
        for degree in self.education_keywords:
            if degree in text:
                education['degree'] = degree
                break
        
        # æŸ¥æ‰¾æ•™è‚²èƒŒæ™¯ç« èŠ‚
        for marker in self.section_markers['education']:
            pattern = f'{marker}[ï¼š:](.*?)(?=\n\n|å·¥ä½œç»éªŒ|é¡¹ç›®ç»éªŒ|$)'
            match = re.search(pattern, text, re.DOTALL)
            if match:
                edu_text = match.group(1).strip()
                education['school'] = edu_text.split('\n')[0] if edu_text else None
                break
        
        return education
    
    def parse(self, resume_text: str) -> Dict:
        """
        è§£æç®€å†ï¼ˆè§„åˆ™æ–¹æ³•ï¼‰
        
        Returns:
            {
                'basic_info': {...},
                'skills': [...],
                'experience': [...],
                'education': {...},
                'confidence': 0.85  # ç½®ä¿¡åº¦
            }
        """
        result = {
            'basic_info': self.extract_basic_info(resume_text),
            'skills': self.extract_skills(resume_text),
            'experience': self.extract_experience_sections(resume_text),
            'education': self.extract_education(resume_text),
        }
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆæ ¹æ®æå–åˆ°çš„å­—æ®µæ•°é‡ï¼‰
        filled_fields = 0
        total_fields = 4
        
        if result['basic_info']['years_experience'] > 0:
            filled_fields += 1
        if len(result['skills']) > 0:
            filled_fields += 1
        if len(result['experience']) > 0:
            filled_fields += 1
        if result['education']['degree']:
            filled_fields += 1
        
        result['confidence'] = filled_fields / total_fields
        
        return result


class LLMParser:
    """åŸºäºå¤§æ¨¡å‹çš„ç®€å†è§£æå™¨ï¼ˆéœ€è¦è°ƒç”¨ OpenAI APIï¼‰"""
    
    def __init__(self, client):
        """
        Args:
            client: OpenAI client å®ä¾‹
        """
        self.client = client
    
    def parse(self, resume_text: str, model: str = "gpt-4o-mini") -> Dict:
        """
        ä½¿ç”¨å¤§æ¨¡å‹è§£æç®€å†
        
        Returns:
            {
                'basic_info': {...},
                'skills': [...],
                'experience': [...],
                'education': {...},
                'confidence': 1.0
            }
        """
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç®€å†ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜æ–‡å­—ã€‚

ç®€å†å†…å®¹:
{resume_text}

è¯·è¿”å›ä»¥ä¸‹JSONæ ¼å¼:
{{
    "basic_info": {{
        "name": "å§“åï¼ˆå¦‚æœæœ‰ï¼‰",
        "phone": "ç”µè¯ï¼ˆå¦‚æœæœ‰ï¼‰",
        "email": "é‚®ç®±ï¼ˆå¦‚æœæœ‰ï¼‰",
        "years_experience": å·¥ä½œå¹´é™æ•°å­—
    }},
    "skills": ["æŠ€èƒ½1", "æŠ€èƒ½2", "æŠ€èƒ½3"],
    "experience": [
        {{
            "date_range": "æ—¶é—´æ®µ",
            "company": "å…¬å¸å",
            "position": "èŒä½",
            "description": "å·¥ä½œæè¿°"
        }}
    ],
    "education": {{
        "degree": "å­¦å†",
        "school": "å­¦æ ¡",
        "major": "ä¸“ä¸š"
    }}
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†è§£æåŠ©æ‰‹ï¼Œæ“…é•¿ä»ç®€å†ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šçš„è¾“å‡º
                response_format={"type": "json_object"}  # å¼ºåˆ¶è¿”å›JSON
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            result['confidence'] = 1.0  # å¤§æ¨¡å‹ç½®ä¿¡åº¦é«˜
            
            return result
            
        except Exception as e:
            print(f"âŒ å¤§æ¨¡å‹è§£æå¤±è´¥: {e}")
            return {
                'basic_info': {},
                'skills': [],
                'experience': [],
                'education': {},
                'confidence': 0.0
            }


class HybridParser:
    """æ··åˆè§£æå™¨ï¼ˆæ¨èï¼‰ï¼šå…ˆç”¨è§„åˆ™ï¼Œå¤±è´¥æ—¶ç”¨å¤§æ¨¡å‹"""
    
    def __init__(self, openai_client=None):
        self.rule_parser = RuleBasedParser()
        self.llm_parser = LLMParser(openai_client) if openai_client else None
        self.confidence_threshold = 0.6  # ç½®ä¿¡åº¦é˜ˆå€¼
    
    def parse(self, resume_text: str, force_llm: bool = False) -> Dict:
        """
        æ··åˆè§£æ
        
        Args:
            resume_text: ç®€å†æ–‡æœ¬
            force_llm: å¼ºåˆ¶ä½¿ç”¨å¤§æ¨¡å‹
        
        Returns:
            è§£æç»“æœ
        """
        # 1. å…ˆç”¨è§„åˆ™è§£æ
        if not force_llm:
            print("ğŸ”§ ä½¿ç”¨è§„åˆ™è§£æ...")
            result = self.rule_parser.parse(resume_text)
            
            print(f"   ç½®ä¿¡åº¦: {result['confidence']*100:.0f}%")
            
            # 2. å¦‚æœç½®ä¿¡åº¦è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
            if result['confidence'] >= self.confidence_threshold:
                print("âœ… è§„åˆ™è§£ææˆåŠŸ")
                return result
            else:
                print(f"âš ï¸  è§„åˆ™è§£æç½®ä¿¡åº¦ä½ ({result['confidence']*100:.0f}%)")
        
        # 3. ç½®ä¿¡åº¦ä¸å¤Ÿæˆ–å¼ºåˆ¶ä½¿ç”¨ï¼Œè°ƒç”¨å¤§æ¨¡å‹
        if self.llm_parser:
            print("ğŸ¤– è°ƒç”¨å¤§æ¨¡å‹è§£æ...")
            result = self.llm_parser.parse(resume_text)
            print("âœ… å¤§æ¨¡å‹è§£æå®Œæˆ")
            return result
        else:
            print("âš ï¸  æœªé…ç½®å¤§æ¨¡å‹ï¼Œè¿”å›è§„åˆ™è§£æç»“æœ")
            return self.rule_parser.parse(resume_text)


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================
if __name__ == '__main__':
    test_resume = """
    å¼ ä¸‰
    ç”µè¯: 13812345678
    é‚®ç®±: zhangsan@example.com
    
    ä¸ªäººç®€ä»‹:
    èµ„æ·±Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œæ‹¥æœ‰5å¹´äº’è”ç½‘å¼€å‘ç»éªŒã€‚
    
    ä¸“ä¸šæŠ€èƒ½:
    - ç²¾é€šPythonã€ç†Ÿæ‚‰Java
    - ç†Ÿç»ƒä½¿ç”¨Djangoã€FastAPIæ¡†æ¶
    - æŒæ¡MySQLã€PostgreSQLã€Redis
    - äº†è§£Dockerã€Kuberneteså®¹å™¨æŠ€æœ¯
    - ç†Ÿæ‚‰RESTful APIè®¾è®¡ã€å¾®æœåŠ¡æ¶æ„
    
    å·¥ä½œç»éªŒ:
    2020.03 - è‡³ä»Š  è…¾è®¯ç§‘æŠ€  é«˜çº§åç«¯å·¥ç¨‹å¸ˆ
    è´Ÿè´£å…¬å¸æ ¸å¿ƒä¸šåŠ¡åç«¯æœåŠ¡å¼€å‘ï¼Œä½¿ç”¨Djangoæ¡†æ¶æ„å»ºé«˜å¹¶å‘APIæœåŠ¡ã€‚
    å‚ä¸å¾®æœåŠ¡æ¶æ„æ”¹é€ ï¼Œä½¿ç”¨Dockerè¿›è¡Œå®¹å™¨åŒ–éƒ¨ç½²ã€‚
    
    2018.06 - 2020.02  é˜¿é‡Œå·´å·´  åç«¯å¼€å‘å·¥ç¨‹å¸ˆ
    è´Ÿè´£ç”µå•†å¹³å°åç«¯å¼€å‘ï¼Œå¤„ç†æ—¥å‡ç™¾ä¸‡çº§è¯·æ±‚ã€‚
    ä½¿ç”¨Redisä¼˜åŒ–ç¼“å­˜ï¼Œæå‡ç³»ç»Ÿæ€§èƒ½30%ã€‚
    
    æ•™è‚²èƒŒæ™¯:
    2014.09 - 2018.06  æ¸…åå¤§å­¦  è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯  æœ¬ç§‘
    """
    
    print("=" * 70)
    print("ç®€å†è§£æå™¨æµ‹è¯•")
    print("=" * 70)
    
    # æµ‹è¯•è§„åˆ™è§£æ
    print("\nã€æµ‹è¯•1: è§„åˆ™è§£æã€‘")
    print("-" * 70)
    rule_parser = RuleBasedParser()
    result = rule_parser.parse(test_resume)
    
    print(f"\nåŸºæœ¬ä¿¡æ¯:")
    print(f"  ç”µè¯: {result['basic_info']['phone']}")
    print(f"  é‚®ç®±: {result['basic_info']['email']}")
    print(f"  å·¥ä½œå¹´é™: {result['basic_info']['years_experience']}å¹´")
    
    print(f"\næŠ€èƒ½åˆ—è¡¨ ({len(result['skills'])}é¡¹):")
    for skill in result['skills'][:10]:
        print(f"  â€¢ {skill}")
    
    print(f"\nå·¥ä½œç»éªŒ ({len(result['experience'])}æ®µ):")
    for exp in result['experience']:
        print(f"  â€¢ {exp['date_range']} - {exp['company']}")
    
    print(f"\næ•™è‚²èƒŒæ™¯:")
    print(f"  å­¦å†: {result['education']['degree']}")
    print(f"  å­¦æ ¡: {result['education']['school']}")
    
    print(f"\nç½®ä¿¡åº¦: {result['confidence']*100:.0f}%")
    
    print("\n" + "=" * 70)
    print("âœ… è§„åˆ™è§£æå®Œæˆï¼æ— éœ€è°ƒç”¨å¤§æ¨¡å‹APIï¼Œæˆæœ¬ä¸º0")
    print("=" * 70)
