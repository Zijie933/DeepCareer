"""
æ™ºèƒ½åŒ¹é…å¼•æ“ - ä¸šç•Œæœ€ä½³å®è·µ
ç»“åˆç»“æ„åŒ–åŒ¹é… + è¯­ä¹‰åŒ¹é… + å…³é”®è¯åŒ¹é…
"""
import re
from typing import List, Dict, Tuple
from sentence_transformers import SentenceTransformer
from numpy import dot
from numpy.linalg import norm
import jieba
import jieba.analyse


class SmartMatcher:
    """æ™ºèƒ½ç®€å†-èŒä½åŒ¹é…å™¨"""
    
    def __init__(self, model_name: str = "shibing624/text2vec-base-chinese"):
        """åˆå§‹åŒ–åŒ¹é…å™¨"""
        self.model = SentenceTransformer(model_name)
        
        # æŠ€æœ¯æ ˆå…³é”®è¯åº“ï¼ˆå¯æ‰©å±•ï¼‰
        self.tech_keywords = {
            'backend': ['Python', 'Java', 'Go', 'Node.js', 'Django', 'FastAPI', 'Spring', 'Flask'],
            'frontend': ['React', 'Vue', 'Angular', 'JavaScript', 'TypeScript', 'HTML', 'CSS'],
            'database': ['MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'SQL Server'],
            'devops': ['Docker', 'Kubernetes', 'Jenkins', 'CI/CD', 'AWS', 'Azure', 'Linux'],
            'architecture': ['å¾®æœåŠ¡', 'åˆ†å¸ƒå¼', 'é«˜å¹¶å‘', 'RESTful', 'gRPC', 'æ¶ˆæ¯é˜Ÿåˆ—']
        }
    
    def extract_keywords(self, text: str, top_k: int = 20) -> List[str]:
        """æå–å…³é”®è¯"""
        # ä½¿ç”¨ jieba æå–å…³é”®è¯
        keywords = jieba.analyse.extract_tags(text, topK=top_k, withWeight=False)
        return keywords
    
    def extract_years_experience(self, text: str) -> int:
        """æå–å·¥ä½œå¹´é™"""
        patterns = [
            r'(\d+)\s*å¹´.*?ç»éªŒ',
            r'(\d+)\s*å¹´.*?å·¥ä½œ',
            r'(\d+)\+?\s*years?',
        ]
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return int(match.group(1))
        return 0
    
    def extract_tech_stack(self, text: str) -> Dict[str, List[str]]:
        """æå–æŠ€æœ¯æ ˆï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰"""
        found_tech = {category: [] for category in self.tech_keywords.keys()}
        
        text_lower = text.lower()
        for category, keywords in self.tech_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower or keyword in text:
                    found_tech[category].append(keyword)
        
        return {k: v for k, v in found_tech.items() if v}  # åªè¿”å›éç©ºçš„
    
    def keyword_match_score(self, resume_keywords: List[str], job_keywords: List[str]) -> float:
        """å…³é”®è¯åŒ¹é…åˆ†æ•°ï¼ˆJaccard ç›¸ä¼¼åº¦ï¼‰"""
        if not job_keywords:
            return 0.0
        
        resume_set = set(kw.lower() for kw in resume_keywords)
        job_set = set(kw.lower() for kw in job_keywords)
        
        intersection = len(resume_set & job_set)
        union = len(resume_set | job_set)
        
        return intersection / union if union > 0 else 0.0
    
    def tech_stack_match_score(self, resume_tech: Dict[str, List[str]], 
                               job_tech: Dict[str, List[str]]) -> float:
        """æŠ€æœ¯æ ˆåŒ¹é…åˆ†æ•°"""
        if not job_tech:
            return 0.0
        
        total_score = 0.0
        category_count = 0
        
        for category, job_skills in job_tech.items():
            resume_skills = resume_tech.get(category, [])
            if job_skills:
                category_count += 1
                # è®¡ç®—è¯¥ç±»åˆ«çš„åŒ¹é…åº¦
                match_count = len(set(job_skills) & set(resume_skills))
                category_score = match_count / len(job_skills)
                total_score += category_score
        
        return total_score / category_count if category_count > 0 else 0.0
    
    def semantic_similarity(self, text1: str, text2: str) -> float:
        """è¯­ä¹‰ç›¸ä¼¼åº¦"""
        emb1 = self.model.encode(text1)
        emb2 = self.model.encode(text2)
        return dot(emb1, emb2) / (norm(emb1) * norm(emb2))
    
    def section_match_score(self, resume_sections: Dict[str, str], 
                           job_sections: Dict[str, str],
                           weights: Dict[str, float] = None) -> float:
        """åˆ†æ®µåŒ¹é…åˆ†æ•°"""
        if weights is None:
            weights = {
                'skills': 0.4,
                'experience': 0.3,
                'education': 0.2,
                'other': 0.1
            }
        
        total_score = 0.0
        total_weight = 0.0
        
        for section, job_text in job_sections.items():
            resume_text = resume_sections.get(section, "")
            if resume_text and job_text:
                sim = self.semantic_similarity(resume_text, job_text)
                weight = weights.get(section, 0.1)
                total_score += sim * weight
                total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def comprehensive_match(self, resume: Dict, job: Dict) -> Dict[str, float]:
        """
        ç»¼åˆåŒ¹é…ï¼ˆä¸šç•Œæœ€ä½³å®è·µï¼‰
        
        Args:
            resume: {
                'full_text': 'å®Œæ•´ç®€å†æ–‡æœ¬',
                'skills': 'æŠ€èƒ½æè¿°',
                'experience': 'å·¥ä½œç»éªŒ',
                'education': 'æ•™è‚²èƒŒæ™¯'
            }
            job: {
                'full_text': 'å®Œæ•´èŒä½æè¿°',
                'requirements': 'ä»»èŒè¦æ±‚',
                'responsibilities': 'å²—ä½èŒè´£'
            }
        
        Returns:
            {
                'total_score': 0.85,      # æ€»åˆ†
                'keyword_score': 0.75,    # å…³é”®è¯åŒ¹é…
                'tech_score': 0.90,       # æŠ€æœ¯æ ˆåŒ¹é…
                'semantic_score': 0.88,   # è¯­ä¹‰åŒ¹é…
                'experience_score': 1.0,  # ç»éªŒåŒ¹é…
                'breakdown': {...}        # è¯¦ç»†åˆ†è§£
            }
        """
        # 1. å…³é”®è¯åŒ¹é…
        resume_keywords = self.extract_keywords(resume['full_text'])
        job_keywords = self.extract_keywords(job['full_text'])
        keyword_score = self.keyword_match_score(resume_keywords, job_keywords)
        
        # 2. æŠ€æœ¯æ ˆåŒ¹é…
        resume_tech = self.extract_tech_stack(resume['full_text'])
        job_tech = self.extract_tech_stack(job['full_text'])
        tech_score = self.tech_stack_match_score(resume_tech, job_tech)
        
        # 3. å·¥ä½œå¹´é™åŒ¹é…
        resume_years = self.extract_years_experience(resume['full_text'])
        job_years = self.extract_years_experience(job['full_text'])
        if job_years > 0:
            experience_score = min(resume_years / job_years, 1.0)
        else:
            experience_score = 0.5  # æ²¡æœ‰æ˜ç¡®å¹´é™è¦æ±‚
        
        # 4. åˆ†æ®µè¯­ä¹‰åŒ¹é…
        resume_sections = {
            'skills': resume.get('skills', ''),
            'experience': resume.get('experience', '')
        }
        job_sections = {
            'skills': job.get('requirements', ''),
            'experience': job.get('responsibilities', '')
        }
        semantic_score = self.section_match_score(resume_sections, job_sections)
        
        # 5. ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        weights = {
            'tech': 0.35,        # æŠ€æœ¯æ ˆåŒ¹é…æœ€é‡è¦
            'semantic': 0.30,    # è¯­ä¹‰åŒ¹é…
            'keyword': 0.20,     # å…³é”®è¯åŒ¹é…
            'experience': 0.15   # ç»éªŒåŒ¹é…
        }
        
        total_score = (
            tech_score * weights['tech'] +
            semantic_score * weights['semantic'] +
            keyword_score * weights['keyword'] +
            experience_score * weights['experience']
        )
        
        return {
            'total_score': round(total_score, 3),
            'tech_score': round(tech_score, 3),
            'semantic_score': round(semantic_score, 3),
            'keyword_score': round(keyword_score, 3),
            'experience_score': round(experience_score, 3),
            'breakdown': {
                'resume_keywords': resume_keywords[:10],
                'job_keywords': job_keywords[:10],
                'resume_tech': resume_tech,
                'job_tech': job_tech,
                'resume_years': resume_years,
                'job_years': job_years
            }
        }


if __name__ == '__main__':
    # æµ‹è¯•
    import os
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    
    print("=" * 70)
    print("æ™ºèƒ½åŒ¹é…å¼•æ“æµ‹è¯•")
    print("=" * 70)
    
    matcher = SmartMatcher()
    
    # æµ‹è¯•ç®€å†
    resume = {
        'full_text': """
        èµ„æ·±Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œ5å¹´å·¥ä½œç»éªŒã€‚ç²¾é€šDjangoã€FastAPIæ¡†æ¶ï¼Œ
        è´Ÿè´£è®¾è®¡å’Œå¼€å‘é«˜å¹¶å‘WebæœåŠ¡å’ŒRESTful APIã€‚ç†Ÿç»ƒä½¿ç”¨PostgreSQLã€
        MySQLæ•°æ®åº“ï¼ŒæŒæ¡Redisç¼“å­˜æŠ€æœ¯ã€‚æœ‰å¾®æœåŠ¡æ¶æ„å®è·µç»éªŒï¼Œä½¿ç”¨
        Dockerå’ŒKubernetesè¿›è¡Œå®¹å™¨åŒ–éƒ¨ç½²ã€‚æ³¨é‡ä»£ç è´¨é‡å’Œå•å…ƒæµ‹è¯•ã€‚
        """,
        'skills': 'Python, Django, FastAPI, PostgreSQL, MySQL, Redis, Docker, Kubernetes',
        'experience': '5å¹´åç«¯å¼€å‘ç»éªŒï¼Œè´Ÿè´£é«˜å¹¶å‘ç³»ç»Ÿè®¾è®¡'
    }
    
    # æµ‹è¯•èŒä½
    jobs = [
        {
            'name': 'Pythonåç«¯å·¥ç¨‹å¸ˆï¼ˆé«˜åŒ¹é…ï¼‰',
            'full_text': 'æ‹›è˜Pythonåç«¯å·¥ç¨‹å¸ˆï¼Œ3å¹´ä»¥ä¸Šç»éªŒï¼Œç†Ÿæ‚‰Djangoæˆ–FastAPIï¼Œäº†è§£å¾®æœåŠ¡',
            'requirements': 'Python, Django, å¾®æœåŠ¡, 3å¹´ç»éªŒ',
            'responsibilities': 'åç«¯APIå¼€å‘ï¼Œç³»ç»Ÿè®¾è®¡'
        },
        {
            'name': 'Javaåç«¯å·¥ç¨‹å¸ˆï¼ˆä½åŒ¹é…ï¼‰',
            'full_text': 'æ‹›è˜Javaå·¥ç¨‹å¸ˆï¼Œç†Ÿæ‚‰Spring Bootã€MyBatisï¼Œæœ‰åˆ†å¸ƒå¼ç»éªŒ',
            'requirements': 'Java, Spring Boot, MyBatis',
            'responsibilities': 'åç«¯æœåŠ¡å¼€å‘'
        },
        {
            'name': 'å‰ç«¯å·¥ç¨‹å¸ˆï¼ˆä½åŒ¹é…ï¼‰',
            'full_text': 'æ‹›è˜å‰ç«¯å·¥ç¨‹å¸ˆï¼Œç²¾é€šReactã€Vueï¼Œæœ‰ç§»åŠ¨ç«¯å¼€å‘ç»éªŒ',
            'requirements': 'React, Vue, JavaScript',
            'responsibilities': 'å‰ç«¯é¡µé¢å¼€å‘'
        }
    ]
    
    print("\nğŸ“„ ç®€å†: Pythonåç«¯å·¥ç¨‹å¸ˆï¼Œ5å¹´ç»éªŒ\n")
    
    results = []
    for job in jobs:
        score = matcher.comprehensive_match(resume, job)
        results.append((job['name'], score))
    
    # æŒ‰åˆ†æ•°æ’åº
    results.sort(key=lambda x: x[1]['total_score'], reverse=True)
    
    print("åŒ¹é…ç»“æœï¼ˆæŒ‰æ€»åˆ†æ’åºï¼‰:")
    print("=" * 70)
    for job_name, score in results:
        total = score['total_score'] * 100
        print(f"\nèŒä½: {job_name}")
        print(f"  æ€»åˆ†: {total:5.1f}%")
        print(f"  â”œâ”€ æŠ€æœ¯æ ˆ: {score['tech_score']*100:5.1f}%")
        print(f"  â”œâ”€ è¯­ä¹‰åŒ¹é…: {score['semantic_score']*100:5.1f}%")
        print(f"  â”œâ”€ å…³é”®è¯: {score['keyword_score']*100:5.1f}%")
        print(f"  â””â”€ ç»éªŒ: {score['experience_score']*100:5.1f}%")
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆï¼è¿™ä¸ªæ–¹æ¡ˆæ¯”çº¯ Embedding æ›´å‡†ç¡®")
    print("=" * 70)
